{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb24aeb1-e719-4dd6-a56a-1c92caa2a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting pandas\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bb/30/f6f1f1ac36250f50c421b1b6af08c35e5a8b5a84385ef928625336b93e6f/pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch1.8/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch1.8/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pytz, numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c41dc07-b033-40de-9757-b6044f6b8162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting transformers\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/79/e1/dcba5ba74392015ceeababf3455138f5875202e66e3316d7ca223bdb7b1c/transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/92/27/1a30d8082ef3c8615ae198b9d451fafffdab815b96727ec3c06befc27ebe/huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "Collecting requests\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c3/20/748e38b466e0819491f0ce6e90ebe4184966ee304fe483e2c414b0f4ef07/requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7d/39/472f2554a0f1e825bd7c5afc11c817cd7a2f3657460f7159f691fbb37c51/PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/38/7f/3ba803bd6d726d65e480bee2aaeea79580d2e4836e4c6ebc27144c62ce51/safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/93/6c/3d801cd9c4d1e18d155cf55f4f1ec37ed2e0a5b52962d4622ee80032ed3d/regex-2024.5.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0f/cb/8fc733c8f251bac1e5c4ae52458c353b3faa98f41d734c226cad3783da03/tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch1.8/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Collecting filelock\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/41/24/0b023b6537dfc9bae2c779353998e3e99ac7dfff4222fc6126650e93c3f3/filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch1.8/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (3.10.0.1)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, pyyaml, packaging, fsspec, filelock, huggingface-hub, tokenizers, safetensors, regex, transformers\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.1 idna-3.7 packaging-24.0 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.2 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.1 urllib3-2.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423eb77-2a43-4d9c-888b-74496d45e3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b6ea05-629c-4d16-b5ff-94b63ce04d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch1.8/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "labels = {'white': 0, 'sex': 1, 'scam': 2, 'gamble': 3, 'black': 4}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [text for text in df['combined']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = tokenizer(text, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # 去掉批次维度\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "        token_type_ids = encoding['token_type_ids'].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8bec9d-1827-43cb-ada4-47774b62142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8749d93d-4173-4bf7-98d6-7f91f3629431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    train_dataset, val_dataset = Dataset(train_data), Dataset(val_data)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input in tqdm(train_dataloader):\n",
    "            train_label = train_input['labels'].to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        with torch.no_grad():\n",
    "            for val_input in val_dataloader:\n",
    "                val_label = val_input['labels'].to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f} \n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f} \n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14249841-5e67-410d-9a14-e0c5db693fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    test_dataset = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input in test_dataloader:\n",
    "            test_label = test_input['labels'].to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].to(device)\n",
    "            output = model(input_id, mask)\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4342422-d7cf-4867-800f-b84ae9410778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch1.8/lib/python3.9/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795 99 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:09<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.795 \n",
      "              | Train Accuracy:  0.294 \n",
      "              | Val Loss:  0.777 \n",
      "              | Val Accuracy:  0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:09<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.763 \n",
      "              | Train Accuracy:  0.367 \n",
      "              | Val Loss:  0.721 \n",
      "              | Val Accuracy:  0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.713 \n",
      "              | Train Accuracy:  0.424 \n",
      "              | Val Loss:  0.663 \n",
      "              | Val Accuracy:  0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:09<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.642 \n",
      "              | Train Accuracy:  0.507 \n",
      "              | Val Loss:  0.596 \n",
      "              | Val Accuracy:  0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:11<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.551 \n",
      "              | Train Accuracy:  0.629 \n",
      "              | Val Loss:  0.539 \n",
      "              | Val Accuracy:  0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.436 \n",
      "              | Train Accuracy:  0.776 \n",
      "              | Val Loss:  0.522 \n",
      "              | Val Accuracy:  0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:13<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.354 \n",
      "              | Train Accuracy:  0.840 \n",
      "              | Val Loss:  0.433 \n",
      "              | Val Accuracy:  0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:11<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.275 \n",
      "              | Train Accuracy:  0.903 \n",
      "              | Val Loss:  0.396 \n",
      "              | Val Accuracy:  0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:12<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.208 \n",
      "              | Train Accuracy:  0.936 \n",
      "              | Val Loss:  0.381 \n",
      "              | Val Accuracy:  0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:11<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.157 \n",
      "              | Train Accuracy:  0.964 \n",
      "              | Val Loss:  0.354 \n",
      "              | Val Accuracy:  0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:10<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 \n",
      "              | Train Loss:  0.114 \n",
      "              | Train Accuracy:  0.977 \n",
      "              | Val Loss:  0.336 \n",
      "              | Val Accuracy:  0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:10<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 \n",
      "              | Train Loss:  0.083 \n",
      "              | Train Accuracy:  0.985 \n",
      "              | Val Loss:  0.346 \n",
      "              | Val Accuracy:  0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:12<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 \n",
      "              | Train Loss:  0.064 \n",
      "              | Train Accuracy:  0.987 \n",
      "              | Val Loss:  0.330 \n",
      "              | Val Accuracy:  0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:12<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 14 \n",
      "              | Train Loss:  0.052 \n",
      "              | Train Accuracy:  0.989 \n",
      "              | Val Loss:  0.321 \n",
      "              | Val Accuracy:  0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:11<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 \n",
      "              | Train Loss:  0.043 \n",
      "              | Train Accuracy:  0.989 \n",
      "              | Val Loss:  0.374 \n",
      "              | Val Accuracy:  0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:09<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 16 \n",
      "              | Train Loss:  0.034 \n",
      "              | Train Accuracy:  0.991 \n",
      "              | Val Loss:  0.352 \n",
      "              | Val Accuracy:  0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:13<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 17 \n",
      "              | Train Loss:  0.029 \n",
      "              | Train Accuracy:  0.990 \n",
      "              | Val Loss:  0.360 \n",
      "              | Val Accuracy:  0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:12<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 18 \n",
      "              | Train Loss:  0.025 \n",
      "              | Train Accuracy:  0.992 \n",
      "              | Val Loss:  0.405 \n",
      "              | Val Accuracy:  0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [02:08<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 19 \n",
      "              | Train Loss:  0.023 \n",
      "              | Train Accuracy:  0.992 \n",
      "              | Val Loss:  0.552 \n",
      "              | Val Accuracy:  0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 38/398 [00:12<01:48,  3.31it/s]"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bert_dataset.csv')\n",
    "\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8 * len(df)), int(.9 * len(df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "EPOCHS = 50\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "train(model, df_train, df_val, LR, EPOCHS)\n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75247557-02a0-48e8-b778-9b218a2111ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8",
   "language": "python",
   "name": "torch1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
